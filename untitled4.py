# -*- coding: utf-8 -*-
"""Untitled4.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1N3lvfu20wQfK1w7yYsjsOGrjACLz22vw
"""

import torch
from transformers import T5ForConditionalGeneration, T5Tokenizer
#Load pre-trained T5 model and tokenizer
model_name = "t5-small"
model = T5ForConditionalGeneration.from_pretrained(model_name)
tokenizer = T5Tokenizer.from_pretrained(model_name)
#Function to summarize text
def summarize_text(text):
    inputs = tokenizer("summarize: " + text, return_tensors="pt", max_length=512,
    truncation=True)
    summary_ids = model.generate(inputs.input_ids, max_length=150, min_length=50,
    length_penalty=2.0, num_beams=4, early_stopping=True)
    summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)
    return summary
# Example text
text = "This is an example text that will be summarized."
# Call the summarizer function
summary = summarize_text(text)
print("Summary:", summary)

